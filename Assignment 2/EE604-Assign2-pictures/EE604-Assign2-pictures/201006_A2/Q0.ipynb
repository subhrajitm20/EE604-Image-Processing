{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install opencv-python\n",
    "%pip install pillow\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install matplotlib\n",
    "%pip install tensorflow==2.10\n",
    "%pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all necessary libraries\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "img_width, img_height = 224, 224\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = '/home/subhrajit/Desktop/EE604/Assignment 2/datathonindoml-2022/train/train'\n",
    "validation_data_dir = '/home/subhrajit/Desktop/EE604/Assignment 2/datathonindoml-2022/validation/validation'\n",
    "nb_train_samples =16000\n",
    "nb_validation_samples = 900\n",
    "epochs = 10\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "\tinput_shape = (3, img_width, img_height)\n",
    "else:\n",
    "\tinput_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CNN Model Design\n",
    "# Hyperparameter tuning\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (2, 2), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1)) # 16\n",
    "model.add(Activation('sigmoid'))  # softmax activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN -> Forward Propagation and Backward Porpagation\n",
    "\n",
    "model.compile(loss='binary_crossentropy', # sparse categorical cross entropy -> multiclass classification\n",
    "\t\t\toptimizer='rmsprop', # 'adam' optimizer\n",
    "\t\t\tmetrics=['accuracy'])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image -> 3D array\n",
    "# Data Preprocessing\n",
    "# Image -> Numpy Arrays (should be a correct input to CNN)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "\trescale=1 / 255, # (0->255) -> (0->1)\n",
    "\tshear_range=0.2,\n",
    "\tzoom_range=0.2,\n",
    "\thorizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "\ttrain_data_dir,\n",
    "\ttarget_size=(img_width, img_height),\n",
    "\tbatch_size=batch_size,\n",
    "\tclass_mode='binary') # binary classification\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory( # validation_data -> numpy array 3D -> . . . . -> [] -> CNN\n",
    "\tvalidation_data_dir,\n",
    "\ttarget_size=(img_width, img_height),\n",
    "\tbatch_size=batch_size,\n",
    "\tclass_mode='binary') # multiclass classification\n",
    "\n",
    "# Model Trained\n",
    "# Labels not used ??\n",
    "\n",
    "model.fit_generator( # fit -> multiclass classification # -> model  parameters tune so that it fits the data with minimum loss function\n",
    "\ttrain_generator,\n",
    "\tsteps_per_epoch=nb_train_samples // batch_size,\n",
    "\tepochs=epochs,\n",
    "\tvalidation_data=validation_generator,\n",
    "\tvalidation_steps=nb_validation_samples // batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model_saved.h5')  # learnable parameters store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "# took 1 image -> predicted its class using model\n",
    "model = load_model('model_saved.h5')\n",
    "\n",
    "image = load_img('v_data/test/planes/5.jpg', target_size=(224, 224))\n",
    "img = np.array(image)\n",
    "img = img / 255.0\n",
    "img = img.reshape(1,224,224,3)\n",
    "label = model.predict(img)\n",
    "print(\"Predicted Class (0 - Yes , 1- No): \", label[0][0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import ast\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import PIL.Image\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# sys.path.insert(0, '..')\n",
    "# from pytorch_image_classification import (\n",
    "#     get_default_config,\n",
    "#     create_model,\n",
    "#     create_transform,\n",
    "# )\n",
    "# config = get_default_config()\n",
    "# config.merge_from_file('../configs/imagenet/resnet18.yaml')\n",
    "# device = torch.device(config.device)\n",
    "\n",
    "# model = create_model(config)\n",
    "# checkpoint = torch.load(\n",
    "#     '../experiments/imagenet/resnet18/exp00/checkpoint_00090.pth')\n",
    "\n",
    "# model.load_state_dict(checkpoint['model'])\n",
    "# model.to(device)\n",
    "# _ = model.eval()\n",
    "# transform = create_transform(config, is_train=False)\n",
    "# %%capture\n",
    "# !wget https://gist.githubusercontent.com/yrevar/942d3a0ac09ec9e5eb3a/raw/238f720ff059c1f82f368259d1ca4ffa5dd8f9f5/imagenet1000_clsidx_to_labels.txt\n",
    "# with open('imagenet1000_clsidx_to_labels.txt') as f:\n",
    "#     index2label = ast.literal_eval(f.read())\n",
    "# %%capture\n",
    "# !wget https://images.pexels.com/photos/2071873/pexels-photo-2071873.jpeg\n",
    "# image = cv2.imread('pexels-photo-2071873.jpeg')\n",
    "# plt.imshow(image[:, :, ::-1])\n",
    "# plt.show()\n",
    "\n",
    "# data = transform(PIL.Image.fromarray(image))\n",
    "# with torch.no_grad():\n",
    "#     pred = model(data.unsqueeze(0).to(device))\n",
    "# prob = F.softmax(pred, dim=1).cpu()\n",
    "\n",
    "# scores, indices = prob.topk(k=5)\n",
    "# scores = scores.numpy().ravel()\n",
    "\n",
    "# indices = indices.numpy().ravel()\n",
    "# names = [index2label[index] for index in indices]\n",
    "# pd.DataFrame({'label': names, 'score': scores})\n",
    "# label\tscore\n",
    "# 0\tEgyptian cat\t0.836771\n",
    "# 1\tlynx, catamount\t0.022285\n",
    "# 2\ttabby, tabby cat\t0.020165\n",
    "# 3\tSiamese cat, Siamese\t0.017015\n",
    "# 4\ttiger cat\t0.007150\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
